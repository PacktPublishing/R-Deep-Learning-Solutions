require(caret)
reduceImage<-function(actds, n.pixel.x=16, n.pixel.y=16){
actImage<-matrix(actds, ncol=28, byrow=FALSE)
img.col.mat <- imappend(list(as.cimg(actImage)),"c")
thmb <- resize(img.col.mat, n.pixel.x, n.pixel.y)
outputImage<-matrix(thmb[,,1,1], nrow = 1, byrow = F)
return(outputImage)
}
require(imager)
trainData<-t(apply(mnist$train$images, 1, FUN=reduceImage))
validData<-t(apply(mnist$test$images, 1, FUN=reduceImage))
labels=mnist$train$labels
labels_valid<-mnist$test$labels
rm(mnist)
n_input<-16
step_size<-16
n.hidden<-64
n.class<-10
lr<-0.01
batch<-500
iteration = 100
bidirectionRNN<-function(x, weights, bias){
x = tf$unstack(x, step_size, 1)
rnn_cell_forward = tf$contrib$rnn$BasicRNNCell(n.hidden)
rnn_cell_backward = tf$contrib$rnn$BasicRNNCell(n.hidden)
cell_output =
tf$contrib$rnn$static_bidirectional_rnn(rnn_cell_forward,
rnn_cell_backward, x, dtype=tf$float32)
last_vec=tail(cell_output[[1]], n=1)[[1]]
return(tf$matmul(last_vec, weights) + bias)
}
eval_acc<-function(yhat, y){
correct_Count = tf$equal(tf$argmax(yhat,1L), tf$argmax(y,1L))
mean_accuracy = tf$reduce_mean(tf$cast(correct_Count,
tf$float32))
return(mean_accuracy)
}
with(tf$name_scope('input'), {
x = tf$placeholder(tf$float32, shape=shape(NULL, step_size,
n_input), name='x')
y <- tf$placeholder(tf$float32, shape(NULL, n.class), name='y')
weights <- tf$Variable(tf$random_normal(shape(n.hidden, n.class)))
bias <- tf$Variable(tf$random_normal(shape(n.class)))
})
yhat = bidirectionRNN(x, weights, bias)
dim(trainData)
print(x)
print(weights)
with(tf$name_scope('input'), {
x = tf$placeholder(tf$float32, shape=shape(NULL, step_size,
n_input), name='x')
y <- tf$placeholder(tf$float32, shape(NULL, n.class), name='y')
weights <- tf$Variable(tf$random_normal(shape(2*n.hidden, n.class)))
bias <- tf$Variable(tf$random_normal(shape(n.class)))
})
yhat = bidirectionRNN(x, weights, bias)
library(tensorflow)
datasets <- tf$contrib$learn$datasets
mnist <- datasets$mnist$read_data_sets("MNIST-data", one_hot =
TRUE)
tf$reset_default_graph()
sess<-tf$InteractiveSession()
reduceImage<-function(actds, n.pixel.x=16, n.pixel.y=16){
actImage<-matrix(actds, ncol=28, byrow=FALSE)
img.col.mat <- imappend(list(as.cimg(actImage)),"c")
thmb <- resize(img.col.mat, n.pixel.x, n.pixel.y)
outputImage<-matrix(thmb[,,1,1], nrow = 1, byrow = F)
return(outputImage)
}
require(imager)
require(caret)
trainData<-t(apply(mnist$train$images, 1, FUN=reduceImage))
validData<-t(apply(mnist$test$images, 1, FUN=reduceImage))
labels=mnist$train$labels
labels_valid<-mnist$test$labels
rm(mnist)
labels <- mnist$train$labels
labels_valid <- mnist$test$labels
n_input<-16
step_size<-16
n.hidden<-64
n.class<-10
lr<-0.01
batch<-500
iteration = 100
bidirectionRNN<-function(x, weights, bias){
x = tf$unstack(x, step_size, 1)
rnn_cell_forward = tf$contrib$rnn$BasicRNNCell(n.hidden)
rnn_cell_backward = tf$contrib$rnn$BasicRNNCell(n.hidden)
cell_output =
tf$contrib$rnn$static_bidirectional_rnn(rnn_cell_forward,
rnn_cell_backward, x, dtype=tf$float32)
last_vec=tail(cell_output[[1]], n=1)[[1]]
return(tf$matmul(last_vec, weights) + bias)
}
eval_acc<-function(yhat, y){
correct_Count = tf$equal(tf$argmax(yhat,1L), tf$argmax(y,1L))
mean_accuracy = tf$reduce_mean(tf$cast(correct_Count,
tf$float32))
return(mean_accuracy)
}
with(tf$name_scope('input'), {
# Define placeholder for input data
x = tf$placeholder(tf$float32, shape=shape(NULL, step_size,
n_input), name='x')
y <- tf$placeholder(tf$float32, shape(NULL, n.class), name='y')
# Define Weights and bias
weights <- tf$Variable(tf$random_normal(shape(2*n.hidden, n.class)))
bias <- tf$Variable(tf$random_normal(shape(n.class)))
})
yhat = bidirectionRNN(x, weights, bias)
cost =
tf$reduce_mean(tf$nn$softmax_cross_entropy_with_logits(logits=yhat,labels=y))
optimizer = tf$train$AdamOptimizer(learning_rate=lr)$minimize(cost)
sess$run(tf$global_variables_initializer())
for(i in 1:iteration){
spls <- sample(1:dim(trainData)[1],batch)
sample_data<-trainData[spls,]
sample_y<-labels[spls,]
sample_data=tf$reshape(sample_data, shape(batch, step_size,
n_input))
out<-optimizer$run(feed_dict = dict(x=sample_data$eval(),
y=sample_y))
if (i %% 1 == 0){
cat("iteration - ", i, "Training Loss - ", cost$eval(feed_dict
= dict(x=sample_data$eval(), y=sample_y)), "\n")
}
}
valid_data=tf$reshape(validData, shape(-1, step_size, n_input))
cost$eval(feed_dict=dict(x=valid_data$eval(), y=labels_valid))
plot(cost$eval())
read.cifar.data <- function(filenames,num.images){
images.rgb <- list()
images.lab <- list()
for (f in 1:length(filenames)) {
to.read <- file(paste("Cifar_10/",filenames[f], sep=""), "rb")
for(i in 1:num.images) {
l <- readBin(to.read, integer(), size=1, n=1, endian="big")
r <- as.integer(readBin(to.read, raw(), size=1, n=1024,
endian="big"))
g <- as.integer(readBin(to.read, raw(), size=1, n=1024,
endian="big"))
b <- as.integer(readBin(to.read, raw(), size=1, n=1024,
endian="big"))
index <- num.images * (f-1) + i
images.rgb[[index]] = data.frame(r, g, b)
images.lab[[index]] = l+1
}
close(to.read)
cat("completed :", filenames[f], "\n")
remove(l,r,g,b,f,i,index, to.read)
}
return(list("images.rgb"=images.rgb,"images.lab"=images.lab))
}
cifar_train <- read.cifar.data(filenames = c("data_batch_1","data_batch_2","data_batch_3","data_batch_4", "data_batch_5"),num.images = 5)
setwd("~/")
read.cifar.data <- function(filenames,num.images){
images.rgb <- list()
images.lab <- list()
for (f in 1:length(filenames)) {
to.read <- file(paste("Cifar_10/",filenames[f], sep=""), "rb")
for(i in 1:num.images) {
l <- readBin(to.read, integer(), size=1, n=1, endian="big")
r <- as.integer(readBin(to.read, raw(), size=1, n=1024,
endian="big"))
g <- as.integer(readBin(to.read, raw(), size=1, n=1024,
endian="big"))
b <- as.integer(readBin(to.read, raw(), size=1, n=1024,
endian="big"))
index <- num.images * (f-1) + i
images.rgb[[index]] = data.frame(r, g, b)
images.lab[[index]] = l+1
}
close(to.read)
cat("completed :", filenames[f], "\n")
remove(l,r,g,b,f,i,index, to.read)
}
return(list("images.rgb"=images.rgb,"images.lab"=images.lab))
}
cifar_train <- read.cifar.data(filenames =
c("data_batch_1.bin","data_batch_2.bin","data_batch_3.bin","data_ba
tch_4.bin", "data_batch_5.bin"))
cifar_train <- read.cifar.data(filenames =
c("data_batch_1.bin","data_batch_2.bin","data_batch_3.bin","data_ba
tch_4.bin", "data_batch_5.bin"),num.images = 5)
cifar_train <- read.cifar.data(filenames =
c("data_batch_1.bin","data_batch_2.bin","data_batch_3.bin","data_batch_4.bin", "data_batch_5.bin"),num.images = 5)
images.rgb.train <- cifar_train$images.rgb
images.lab.train <- cifar_train$images.lab
rm(cifar_train)
cifar_test <- read.cifar.data(filenames = c("test_batch.bin"))
images.rgb.test <- cifar_test$images.rgb
images.lab.test <- cifar_test$images.lab
rm(cifar_test)
cifar_test <- read.cifar.data(filenames = c("test_batch.bin"), num.images = 1)
images.rgb.test <- cifar_test$images.rgb
images.lab.test <- cifar_test$images.lab
rm(cifar_test)
flat_data <- function(x_listdata,y_listdata){
x_listdata <- lapply(x_listdata,function(x){unlist(x)})
x_listdata <- do.call(rbind,x_listdata)
y_listdata <- lapply(y_listdata,function(x){a=c(rep(0,10)); a[x]=1;
return(a)})
y_listdata <- do.call(rbind,y_listdata)
return(list("images"=x_listdata, "labels"=y_listdata))
}
train_data <- flat_data(x_listdata = images.rgb.train, y_listdata =
images.lab.train)
test_data <- flat_data(x_listdata = images.rgb.test, y_listdata =
images.lab.test)
labels <- read.table("Cifar_10/batches.meta.txt")
drawImage <- function(index, images.rgb, images.lab=NULL) {
require(imager)
img <- images.rgb[[index]]
img.r.mat <- as.cimg(matrix(img$r, ncol=32, byrow = FALSE))
img.g.mat <- as.cimg(matrix(img$g, ncol=32, byrow = FALSE))
img.b.mat <- as.cimg(matrix(img$b, ncol=32, byrow = FALSE))
img.col.mat <- imappend(list(img.r.mat,img.g.mat,img.b.mat),"c")
if(!is.null(images.lab)){
lab = labels[[1]][images.lab[[index]]]
}
plot(img.col.mat,main=paste0(lab,":32x32 size",sep=" "),xaxt="n")
axis(side=1, xaxp=c(10, 50, 4), las=1)
return(list("Image label" =lab,"Image description" =img.col.mat))
}
drawImage(sample(1:50000, size=1), images.rgb.train,
images.lab.train)
img.col.mat <- imappend(list(img.r.mat,img.g.mat,img.b.mat),"c")
if(!is.null(images.lab)){
lab = labels[[1]][images.lab[[index]]]
}
plot(img.col.mat,main=paste0(lab,":32x32 size",sep=" "),xaxt="n")
axis(side=1, xaxp=c(10, 50, 4), las=1)
return(list("Image label" =lab,"Image description" =img.col.mat))
}
drawImage(sample(1:500, size=1), images.rgb.train,
images.lab.train)
img.col.mat <- imappend(list(img.r.mat,img.g.mat,img.b.mat),"c")
if(!is.null(images.lab)){
lab = labels[[1]][images.lab[[index]]]
}
plot(img.col.mat,main=paste0(lab,":32x32 size",sep=" "),xaxt="n")
axis(side=1, xaxp=c(10, 50, 4), las=1)
return(list("Image label" =lab,"Image description" =img.col.mat))
}
drawImage(sample(1:50, size=1), images.rgb.train,
images.lab.train)
drawImage <- function(index, images.rgb, images.lab=NULL) {
require(imager)
img <- images.rgb[[index]]
img.r.mat <- as.cimg(matrix(img$r, ncol=32, byrow = FALSE))
img.g.mat <- as.cimg(matrix(img$g, ncol=32, byrow = FALSE))
img.b.mat <- as.cimg(matrix(img$b, ncol=32, byrow = FALSE))
img.col.mat <- imappend(list(img.r.mat,img.g.mat,img.b.mat),"c")
if(!is.null(images.lab)){
lab = labels[[1]][images.lab[[index]]]
}
plot(img.col.mat,main=paste0(lab,":32x32 size",sep=" "),xaxt="n")
axis(side=1, xaxp=c(10, 50, 4), las=1)
return(list("Image label" =lab,"Image description" =img.col.mat))
}
drawImage(sample(1:50000, size=1), images.rgb.train,
images.lab.train)
Require(caret)
normalizeObj<-preProcess(train_data$images, method="range")
train_data$images<-predict(normalizeObj, train_data$images)
test_data$images <- predict(normalizeObj, test_data$images)
require(caret)
normalizeObj<-preProcess(train_data$images, method="range")
train_data$images<-predict(normalizeObj, train_data$images)
test_data$images <- predict(normalizeObj, test_data$images)
library(tensorflow)
sess = tf$Session()
x = tf$placeholder(tf$float32, shape=shape(NULL, img_size_flat),
name='x')
library(text2vec)
library(glmnet)
data("movie_review")
logistic_model <- function(Xtrain,Ytrain,Xtest,Ytest)
{
classifier <- cv.glmnet(x=Xtrain, y=Ytrain,
family="binomial", alpha=1, type.measure = "auc",
nfolds = 5, maxit = 1000)
plot(classifier)
vocab_test_pred <- predict(classifier, Xtest, type = "response")
return(cat("Train AUC : ", round(max(classifier$cvm), 4),
"Test AUC : ",glmnet:::auc(Ytest, vocab_test_pred),"\n"))
}
train_samples <-
caret::createDataPartition(c(1:length(labels[1,1])),p =
0.8)$Resample1
label[1,1]
labels[1,1]
labels[,1]
length(labels[1,])
train_samples <-
caret::createDataPartition(c(1:length(labels[,1])),p =
0.8)$Resample1
library(h2o)
require(h2o)
localH2O = h2o.init(ip = "localhost", port = 54321, startH2O =
TRUE,min_mem_size = "20G",nthreads = 8)
localH2O = h2o.init(ip = "localhost", port = 54321, startH2O =
TRUE,min_mem_size = "20G",nthreads = 8)
localH2O = h2o.init(ip = "localhost", port = 54321, nthreads = -1)
load_occupancy_data<-function(train){
xFeatures = c("Temperature", "Humidity", "Light", "CO2",
"HumidityRatio")
yFeatures = "Occupancy"
if(train){
occupancy_ds <-
as.matrix(read.csv("datatraining.txt",stringsAsFactors = T))
} else
{
occupancy_ds <-
as.matrix(read.csv("datatest.txt",stringsAsFactors = T))
}
occupancy_ds<-apply(occupancy_ds[, c(xFeatures, yFeatures)], 2,
FUN=as.numeric)
return(occupancy_ds)
}
occupancy_train <-load_occupancy_data(train=T)
occupancy_test <- load_occupancy_data(train = F)
setwd("~/occupancy_data")
occupancy_train <-load_occupancy_data(train=T)
occupancy_test <- load_occupancy_data(train = F)
ggpairs(occupancy_train$data[, occupancy_train$xFeatures])
require(GGally)
ggpairs(occupancy_train$data[, occupancy_train$xFeatures])
occupancy_train$data<-data.frame(occupancy_train$data)
occupancy_train$data<-data.frame(occupancy_train$data)
setwd("~/")
occupancy_train$data<-data.frame(occupancy_train$data)
img_width = 32L
img_height = 32L
img_shape = c(img_width, img_height)
num_classes = 10L
num_channels = 3L
img_size_flat = img_width * img_height * num_channels
filter_size1 = 5L
num_filters1 = 64L
filter_size2 = 5L
num_filters2 = 64L
fc_size = 1024L
weight_variable <- function(shape) {
initial <- tf$truncated_normal(shape, stddev=0.1)
tf$Variable(initial)
}
bias_variable <- function(shape) {
initial <- tf$constant(0.1, shape=shape)
tf$Variable(initial)
}
create_conv_layer <- function(input,
num_input_channels,
filter_size,
num_filters,
use_pooling=True)
{
shape1 = shape(filter_size, filter_size, num_input_channels,
num_filters)
weights = weight_variable(shape=shape1)
biases = bias_variable(shape=shape(num_filters))
layer = tf$nn$conv2d(input=input,
filter=weights,
strides=shape(1L, 1L, 1L ,1L),
padding="SAME")
layer = layer + biases
if(use_pooling){
layer = tf$nn$max_pool(value=layer,
ksize=shape(1L, 2L, 2L, 1L),
strides=shape(1L, 2L, 2L, 1L),
padding='SAME')
}
layer = tf$nn$relu(layer)
return(list("layer" = layer, "weights" = weights))
}
drawImage_conv <- function(index, images.bw,
images.lab=NULL,par_imgs=8) {
require(imager)
img <- images.bw[index,,,]
n_images <- dim(img)[3]
par(mfrow=c(par_imgs,par_imgs), oma=c(0,0,0,0),
mai=c(0.05,0.05,0.05,0.05),ann=FALSE,ask=FALSE)
for(i in 1:n_images){
img.bwmat <- as.cimg(img[,,i])
if(!is.null(images.lab)){
lab = labels[[1]][images.lab[[index]]]
}
plot(img.bwmat,axes=FALSE,ann=FALSE)
}
par(mfrow=c(1,1))
}
drawImage_conv_weights <- function(weights_conv, par_imgs=8) {
require(imager)
n_images <- dim(weights_conv)[4]
par(mfrow=c(par_imgs,par_imgs), oma=c(0,0,0,0),
mai=c(0.05,0.05,0.05,0.05),ann=FALSE,ask=FALSE)
for(i in 1:n_images){
img.r.mat <- as.cimg(weights_conv[,,1,i])
img.g.mat <- as.cimg(weights_conv[,,2,i])
img.b.mat <- as.cimg(weights_conv[,,3,i])
img.col.mat <- imappend(list(img.r.mat,img.g.mat,img.b.mat),"c")
plot(img.col.mat,axes=FALSE,ann=FALSE)
}
par(mfrow=c(1,1))
}
flatten_conv_layer <- function(layer){
layer_shape = layer$get_shape()
num_channels
num_features =
prod(c(layer_shape$as_list()[[2]],layer_shape$as_list()[[3]],layer_
shape$as_list()[[4]]))
layer_flat = tf$reshape(layer, shape(-1, num_features))
return(list("layer_flat"=layer_flat, "num_features"=num_features))
}
flatten_conv_layer <- function(layer){
layer_shape = layer$get_shape()
num_channels
num_features =
prod(c(layer_shape$as_list()[[2]],layer_shape$as_list()[[3]],layer_shape$as_list()[[4]]))
layer_flat = tf$reshape(layer, shape(-1, num_features))
return(list("layer_flat"=layer_flat, "num_features"=num_features))
}
create_fc_layer <- function(input,
num_inputs,
num_outputs,
use_relu=True)
{
weights = weight_variable(shape=shape(num_inputs, num_outputs))
biases = bias_variable(shape=shape(num_outputs))
layer = tf$matmul(input, weights) + biases
if(use_relu){
layer = tf$nn$relu(layer)
}
return(layer)
}
x = tf$placeholder(tf$float32, shape=shape(NULL, img_size_flat),
name='x')
library(tensorflow)
sess = tf$Session()
x = tf$placeholder(tf$float32, shape=shape(NULL, img_size_flat),
name='x')
x_image = tf$reshape(x, shape(-1L, img_size, img_size,
num_channels))
img_size = 32L
x_image = tf$reshape(x, shape(-1L, img_size, img_size,
num_channels))
y_true = tf$placeholder(tf$float32, shape=shape(NULL, num_classes),
name='y_true')
y_true_cls = tf$argmax(y_true, dimension=1L)
conv1 <- create_conv_layer(input=x_image,
num_input_channels=num_channels,
filter_size=filter_size1,
num_filters=num_filters1,
use_pooling=TRUE)
layer_conv1 <- conv1$layer
conv1_images <- conv1$layer$eval(feed_dict = dict(x = train_data$images, y_true = train_data$labels))
sess = tf$Session()
conv1_images <- conv1$layer$eval(feed_dict = dict(x = train_data$images, y_true = train_data$labels))
conv1_images <- conv1$layer$eval(feed_dict = dict(x = train_data$images, y_true = train_data$labels), session = sess)
install.packages("reticulate")
use_condaenv("python27")
midi <-
import_from_path("midi",path="C:/ProgramData/Anaconda2/Lib/sitepackages")
np <- import("numpy")
msgpack <-
import_from_path("msgpack",path="C:/ProgramData/Anaconda2/Lib/sitepackages")
psys <- import("sys")
tqdm <-
import_from_path("tqdm",path="C:/ProgramData/Anaconda2/Lib/sitepackages")
midi_manipulation_updated <-
import_from_path("midi_manipulation_updated",path="C:/Music_RBM")
glob <- import("glob")
use_condaenv("python27")
library(reticulate)
use_condaenv("python27")
midi <-
import_from_path("midi",path="C:/ProgramData/Anaconda2/Lib/sitepackages")
midi <-
import_from_path("midi",path="C:/ProgramData/Anaconda2/Lib/sitepackages")
psys <- import("sys")
tqdm <-
import_from_path("tqdm",path="C:/ProgramData/Anaconda2/Lib/sitepackages")
tqdm <-
import_from_path("tqdm",path="C:/ProgramData/Anaconda2/Lib/sitepackages")
tqdm <-
import_from_path("tqdm",path="C:/ProgramData/Anaconda2/Lib/sitepackages")
load_occupancy_data<-function(train){
xFeatures = c("Temperature", "Humidity", "Light", "CO2",
"HumidityRatio")
yFeatures = "Occupancy"
if(train){
occupancy_ds <-
as.matrix(read.csv("datatraining.txt",stringsAsFactors = T))
} else
{
occupancy_ds <-
as.matrix(read.csv("datatest.txt",stringsAsFactors = T))
}
occupancy_ds<-apply(occupancy_ds[, c(xFeatures, yFeatures)], 2,
FUN=as.numeric)
return(occupancy_ds)
}
setwd("~/occupancy_data")
occupancy_train<-data.frame(occupancy_train)
occupancy_train <-load_occupancy_data(train=T)
occupancy_test <- load_occupancy_data(train = F)
occupancy_train<-data.frame(occupancy_train)
occupancy_test<-data.frame(occupancy_test)
require(GGally)
ggpairs(occupancy_train$data[, occupancy_train$xFeatures])
occupancy_train$data<-data.frame(occupancy_train$data)
