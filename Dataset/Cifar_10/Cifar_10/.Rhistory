if (i %% 1 == 0){
cat("iteration - ", i, "Training Loss - ", cost$eval(feed_dict
= dict(x=sample_data$eval(), y=sample_y)), "\n")
}
}
valid_data=tf$reshape(validData, shape(-1, step_size, n_input))
cost$eval(feed_dict=dict(x=valid_data$eval(), y=labels_valid))
plot(cost$eval())
read.cifar.data <- function(filenames,num.images){
images.rgb <- list()
images.lab <- list()
for (f in 1:length(filenames)) {
to.read <- file(paste("Cifar_10/",filenames[f], sep=""), "rb")
for(i in 1:num.images) {
l <- readBin(to.read, integer(), size=1, n=1, endian="big")
r <- as.integer(readBin(to.read, raw(), size=1, n=1024,
endian="big"))
g <- as.integer(readBin(to.read, raw(), size=1, n=1024,
endian="big"))
b <- as.integer(readBin(to.read, raw(), size=1, n=1024,
endian="big"))
index <- num.images * (f-1) + i
images.rgb[[index]] = data.frame(r, g, b)
images.lab[[index]] = l+1
}
close(to.read)
cat("completed :", filenames[f], "\n")
remove(l,r,g,b,f,i,index, to.read)
}
return(list("images.rgb"=images.rgb,"images.lab"=images.lab))
}
cifar_train <- read.cifar.data(filenames = c("data_batch_1","data_batch_2","data_batch_3","data_batch_4", "data_batch_5"),num.images = 5)
setwd("~/")
read.cifar.data <- function(filenames,num.images){
images.rgb <- list()
images.lab <- list()
for (f in 1:length(filenames)) {
to.read <- file(paste("Cifar_10/",filenames[f], sep=""), "rb")
for(i in 1:num.images) {
l <- readBin(to.read, integer(), size=1, n=1, endian="big")
r <- as.integer(readBin(to.read, raw(), size=1, n=1024,
endian="big"))
g <- as.integer(readBin(to.read, raw(), size=1, n=1024,
endian="big"))
b <- as.integer(readBin(to.read, raw(), size=1, n=1024,
endian="big"))
index <- num.images * (f-1) + i
images.rgb[[index]] = data.frame(r, g, b)
images.lab[[index]] = l+1
}
close(to.read)
cat("completed :", filenames[f], "\n")
remove(l,r,g,b,f,i,index, to.read)
}
return(list("images.rgb"=images.rgb,"images.lab"=images.lab))
}
cifar_train <- read.cifar.data(filenames =
c("data_batch_1.bin","data_batch_2.bin","data_batch_3.bin","data_ba
tch_4.bin", "data_batch_5.bin"))
cifar_train <- read.cifar.data(filenames =
c("data_batch_1.bin","data_batch_2.bin","data_batch_3.bin","data_ba
tch_4.bin", "data_batch_5.bin"),num.images = 5)
cifar_train <- read.cifar.data(filenames =
c("data_batch_1.bin","data_batch_2.bin","data_batch_3.bin","data_batch_4.bin", "data_batch_5.bin"),num.images = 5)
images.rgb.train <- cifar_train$images.rgb
images.lab.train <- cifar_train$images.lab
rm(cifar_train)
cifar_test <- read.cifar.data(filenames = c("test_batch.bin"))
images.rgb.test <- cifar_test$images.rgb
images.lab.test <- cifar_test$images.lab
rm(cifar_test)
cifar_test <- read.cifar.data(filenames = c("test_batch.bin"), num.images = 1)
images.rgb.test <- cifar_test$images.rgb
images.lab.test <- cifar_test$images.lab
rm(cifar_test)
flat_data <- function(x_listdata,y_listdata){
x_listdata <- lapply(x_listdata,function(x){unlist(x)})
x_listdata <- do.call(rbind,x_listdata)
y_listdata <- lapply(y_listdata,function(x){a=c(rep(0,10)); a[x]=1;
return(a)})
y_listdata <- do.call(rbind,y_listdata)
return(list("images"=x_listdata, "labels"=y_listdata))
}
train_data <- flat_data(x_listdata = images.rgb.train, y_listdata =
images.lab.train)
test_data <- flat_data(x_listdata = images.rgb.test, y_listdata =
images.lab.test)
labels <- read.table("Cifar_10/batches.meta.txt")
drawImage <- function(index, images.rgb, images.lab=NULL) {
require(imager)
img <- images.rgb[[index]]
img.r.mat <- as.cimg(matrix(img$r, ncol=32, byrow = FALSE))
img.g.mat <- as.cimg(matrix(img$g, ncol=32, byrow = FALSE))
img.b.mat <- as.cimg(matrix(img$b, ncol=32, byrow = FALSE))
img.col.mat <- imappend(list(img.r.mat,img.g.mat,img.b.mat),"c")
if(!is.null(images.lab)){
lab = labels[[1]][images.lab[[index]]]
}
plot(img.col.mat,main=paste0(lab,":32x32 size",sep=" "),xaxt="n")
axis(side=1, xaxp=c(10, 50, 4), las=1)
return(list("Image label" =lab,"Image description" =img.col.mat))
}
drawImage(sample(1:50000, size=1), images.rgb.train,
images.lab.train)
img.col.mat <- imappend(list(img.r.mat,img.g.mat,img.b.mat),"c")
if(!is.null(images.lab)){
lab = labels[[1]][images.lab[[index]]]
}
plot(img.col.mat,main=paste0(lab,":32x32 size",sep=" "),xaxt="n")
axis(side=1, xaxp=c(10, 50, 4), las=1)
return(list("Image label" =lab,"Image description" =img.col.mat))
}
drawImage(sample(1:500, size=1), images.rgb.train,
images.lab.train)
img.col.mat <- imappend(list(img.r.mat,img.g.mat,img.b.mat),"c")
if(!is.null(images.lab)){
lab = labels[[1]][images.lab[[index]]]
}
plot(img.col.mat,main=paste0(lab,":32x32 size",sep=" "),xaxt="n")
axis(side=1, xaxp=c(10, 50, 4), las=1)
return(list("Image label" =lab,"Image description" =img.col.mat))
}
drawImage(sample(1:50, size=1), images.rgb.train,
images.lab.train)
drawImage <- function(index, images.rgb, images.lab=NULL) {
require(imager)
img <- images.rgb[[index]]
img.r.mat <- as.cimg(matrix(img$r, ncol=32, byrow = FALSE))
img.g.mat <- as.cimg(matrix(img$g, ncol=32, byrow = FALSE))
img.b.mat <- as.cimg(matrix(img$b, ncol=32, byrow = FALSE))
img.col.mat <- imappend(list(img.r.mat,img.g.mat,img.b.mat),"c")
if(!is.null(images.lab)){
lab = labels[[1]][images.lab[[index]]]
}
plot(img.col.mat,main=paste0(lab,":32x32 size",sep=" "),xaxt="n")
axis(side=1, xaxp=c(10, 50, 4), las=1)
return(list("Image label" =lab,"Image description" =img.col.mat))
}
drawImage(sample(1:50000, size=1), images.rgb.train,
images.lab.train)
Require(caret)
normalizeObj<-preProcess(train_data$images, method="range")
train_data$images<-predict(normalizeObj, train_data$images)
test_data$images <- predict(normalizeObj, test_data$images)
require(caret)
normalizeObj<-preProcess(train_data$images, method="range")
train_data$images<-predict(normalizeObj, train_data$images)
test_data$images <- predict(normalizeObj, test_data$images)
library(tensorflow)
sess = tf$Session()
x = tf$placeholder(tf$float32, shape=shape(NULL, img_size_flat),
name='x')
library(text2vec)
library(glmnet)
data("movie_review")
logistic_model <- function(Xtrain,Ytrain,Xtest,Ytest)
{
classifier <- cv.glmnet(x=Xtrain, y=Ytrain,
family="binomial", alpha=1, type.measure = "auc",
nfolds = 5, maxit = 1000)
plot(classifier)
vocab_test_pred <- predict(classifier, Xtest, type = "response")
return(cat("Train AUC : ", round(max(classifier$cvm), 4),
"Test AUC : ",glmnet:::auc(Ytest, vocab_test_pred),"\n"))
}
train_samples <-
caret::createDataPartition(c(1:length(labels[1,1])),p =
0.8)$Resample1
label[1,1]
labels[1,1]
labels[,1]
length(labels[1,])
train_samples <-
caret::createDataPartition(c(1:length(labels[,1])),p =
0.8)$Resample1
library(h2o)
require(h2o)
localH2O = h2o.init(ip = "localhost", port = 54321, startH2O =
TRUE,min_mem_size = "20G",nthreads = 8)
localH2O = h2o.init(ip = "localhost", port = 54321, startH2O =
TRUE,min_mem_size = "20G",nthreads = 8)
localH2O = h2o.init(ip = "localhost", port = 54321, nthreads = -1)
library(tensorflow)
library(imager)
np <- import("numpy")
tf$reset_default_graph()
sess <- tf$InteractiveSession()
download.cifar.data <- function(data_dir) {
dir.create(data_dir, showWarnings = FALSE)
setwd(data_dir)
if (!file.exists('cifar-10-binary.tar.gz')){
download.file(url='http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz', destfile='cifar-10-binary.tar.gz', method='wget')
untar("cifar-10-binary.tar.gz") # Unzip files
file.remove("cifar-10-binary.tar.gz") # remove zip file
}
setwd("..")
}
download.cifar.data(data_dir="/Cifar_10/")
download.cifar.data(data_dir="Cifar_10/")
read.cifar.data <- function(filenames,num.images=10000){
images.rgb <- list()
images.lab <- list()
for (f in 1:length(filenames)) {
to.read <- file(paste("/Cifar_10/",filenames[f], sep=""), "rb")
for(i in 1:num.images) {
l <- readBin(to.read, integer(), size=1, n=1, endian="big")
r <- as.integer(readBin(to.read, raw(), size=1, n=1024, endian="big"))
g <- as.integer(readBin(to.read, raw(), size=1, n=1024, endian="big"))
b <- as.integer(readBin(to.read, raw(), size=1, n=1024, endian="big"))
index <- num.images * (f-1) + i
images.rgb[[index]] = data.frame(r, g, b)
images.lab[[index]] = l+1
}
close(to.read)
cat("completed :",  filenames[f], "\n")
remove(l,r,g,b,f,i,index, to.read)
}
return(list("images.rgb"=images.rgb,"images.lab"=images.lab))
}
cifar_train <- read.cifar.data(filenames = c("data_batch_1.bin","data_batch_2.bin","data_batch_3.bin","data_batch_4.bin","data_batch_5.bin"))
cifar_train <- read.cifar.data(filenames = c("data_batch_1","data_batch_2.bin","data_batch_3.bin","data_batch_4.bin","data_batch_5.bin"))
read.cifar.data <- function(filenames,num.images=10000){
images.rgb <- list()
images.lab <- list()
for (f in 1:length(filenames)) {
to.read <- file(paste("Cifar_10/",filenames[f], sep=""), "rb")
for(i in 1:num.images) {
l <- readBin(to.read, integer(), size=1, n=1, endian="big")
r <- as.integer(readBin(to.read, raw(), size=1, n=1024, endian="big"))
g <- as.integer(readBin(to.read, raw(), size=1, n=1024, endian="big"))
b <- as.integer(readBin(to.read, raw(), size=1, n=1024, endian="big"))
index <- num.images * (f-1) + i
images.rgb[[index]] = data.frame(r, g, b)
images.lab[[index]] = l+1
}
close(to.read)
cat("completed :",  filenames[f], "\n")
remove(l,r,g,b,f,i,index, to.read)
}
return(list("images.rgb"=images.rgb,"images.lab"=images.lab))
}
cifar_train <- read.cifar.data(filenames = c("data_batch_1","data_batch_2.bin","data_batch_3.bin","data_batch_4.bin","data_batch_5.bin"))
download.cifar.data(data_dir="Cifar_10/")
options( warn = -1 )
download.cifar.data(data_dir="Cifar_10/")
x = tf$placeholder(tf$float32, shape=shape(NULL, img_size_flat), name='x')
require(caret)
normalizeObj<-preProcess(train_data$images, method="range")
train_data$images<-predict(normalizeObj, train_data$images)
test_data$images <- predict(normalizeObj, test_data$images)
norm_data <- apply(train_data$images,1,function(x){
return(data.frame(r=x[1:1024],
g=x[1025:2048],
b=x[2049:3072]))
})
drawImage(124, norm_data, images.lab.train)
filter_size1 = 5L
num_filters1 = 64L
filter_size2 = 5L
num_filters2 = 64L
fc_size = 1024L
img_size = 32L
num_channels = 3L
img_size_flat = img_size * img_size * num_channels
img_shape = c(img_size, img_size)
num_classes = 10L
weight_variable <- function(shape) {
initial <- tf$truncated_normal(shape, stddev=0.1)
tf$Variable(initial)
}
bias_variable <- function(shape) {
initial <- tf$constant(0.1, shape=shape)
tf$Variable(initial)
}
create_conv_layer <- function(input,
num_input_channels,
filter_size,
num_filters,
use_pooling=True)
{
shape1 = shape(filter_size, filter_size, num_input_channels, num_filters)
weights = weight_variable(shape=shape1)
biases = bias_variable(shape=shape(num_filters))
layer = tf$nn$conv2d(input=input,
filter=weights,
strides=shape(1L, 1L, 1L ,1L),
padding="SAME")
layer = layer + biases
if(use_pooling){
layer = tf$nn$max_pool(value=layer,
ksize=shape(1L, 2L, 2L, 1L),
strides=shape(1L, 2L, 2L, 1L),
padding='SAME')
}
layer = tf$nn$relu(layer)
return(list("layer" = layer, "weights" = weights))
}
x = tf$placeholder(tf$float32, shape=shape(NULL, img_size_flat), name='x')
x_image = tf$reshape(x, shape(-1L, img_size, img_size, num_channels))
y_true = tf$placeholder(tf$float32, shape=shape(NULL, num_classes), name='y_true')
y_true_cls = tf$argmax(y_true, dimension=1L)
conv1 <- create_conv_layer(input=x_image,
num_input_channels=num_channels,
filter_size=filter_size1,
num_filters=num_filters1,
use_pooling=TRUE)
layer_conv1 <- conv1$layer
conv1_images <- conv1$layer$eval(feed_dict = dict(x =
train_data$images, y_true = train_data$labels))
conv1 <- create_conv_layer(input=x_image,
num_input_channels=num_channels,
filter_size=filter_size1,
num_filters=num_filters1,
use_pooling=TRUE)
layer_conv1 <- conv1$layer
conv1_images <- conv1$layer$eval(feed_dict = dict(x = train_data$images[1:150,], y_true = train_data$labels[1:150,]))
conv1_images <- conv1$layer$eval(feed_dict = dict(x = train_data$images, y_true = train_data$labels[1:150,]))
labels <- read.table("/Cifar_10/batches.meta.txt")
labels <- read.table("Cifar_10/batches.meta.txt")
setwd("~/Cifar_10")
labels <- read.table("Cifar_10/batches.meta.txt")
labels <- read.table("batches.meta.txt")
conv1_images <- conv1$layer$eval(feed_dict = dict(x = train_data$images, y_true = train_data$labels[1:150,]))
download.cifar.data <- function(data_dir) {
dir.create(data_dir, showWarnings = FALSE)
setwd(data_dir)
if (!file.exists('cifar-10-binary.tar.gz')){
download.file(url='http://www.cs.toronto.edu/~kriz/cifar-10-binary.
tar.gz', destfile='cifar-10-binary.tar.gz', method='wget')
untar("cifar-10-binary.tar.gz") # Unzip files
file.remove("cifar-10-binary.tar.gz") # remove zip file
}
setwd("..")
}
download.cifar.data(data_dir="Cifar_10/")
read.cifar.data <- function(filenames,num.images){
images.rgb <- list()
images.lab <- list()
for (f in 1:length(filenames)) {
to.read <- file(paste("Cifar_10/",filenames[f], sep=""), "rb")
for(i in 1:num.images) {
l <- readBin(to.read, integer(), size=1, n=1, endian="big")
r <- as.integer(readBin(to.read, raw(), size=1, n=1024,
endian="big"))
g <- as.integer(readBin(to.read, raw(), size=1, n=1024,
endian="big"))
b <- as.integer(readBin(to.read, raw(), size=1, n=1024,
endian="big"))
index <- num.images * (f-1) + i
images.rgb[[index]] = data.frame(r, g, b)
images.lab[[index]] = l+1
}
close(to.read)
cat("completed :", filenames[f], "\n")
remove(l,r,g,b,f,i,index, to.read)
}
return(list("images.rgb"=images.rgb,"images.lab"=images.lab))
}
cifar_train <- read.cifar.data(filenames = c("data_batch_1","data_batch_2","data_batch_3","data_batch_4", "data_batch_5"),num.images = 5)
cifar_train <- read.cifar.data(filenames = c("data_batch_1","data_batch_2","data_batch_3","data_batch_4", "data_batch_5"),num.images = 5)
cifar_test <- read.cifar.data(filenames = c("test_batch"), num.images = 1)
img_width = 32L
img_height = 32L
img_shape = c(img_width, img_height)
num_classes = 10L
num_channels = 3L
img_size_flat = img_width * img_height * num_channels
filter_size1 = 5L
num_filters1 = 64L
filter_size2 = 5L
num_filters2 = 64L
fc_size = 1024L
weight_variable <- function(shape) {
initial <- tf$truncated_normal(shape, stddev=0.1)
tf$Variable(initial)
}
bias_variable <- function(shape) {
initial <- tf$constant(0.1, shape=shape)
tf$Variable(initial)
}
create_conv_layer <- function(input,
num_input_channels,
filter_size,
num_filters,
use_pooling=True)
{
shape1 = shape(filter_size, filter_size, num_input_channels,
num_filters)
weights = weight_variable(shape=shape1)
biases = bias_variable(shape=shape(num_filters))
layer = tf$nn$conv2d(input=input,
filter=weights,
strides=shape(1L, 1L, 1L ,1L),
padding="SAME")
layer = layer + biases
if(use_pooling){
layer = tf$nn$max_pool(value=layer,
ksize=shape(1L, 2L, 2L, 1L),
strides=shape(1L, 2L, 2L, 1L),
padding='SAME')
}
layer = tf$nn$relu(layer)
return(list("layer" = layer, "weights" = weights))
}
drawImage_conv <- function(index, images.bw,
images.lab=NULL,par_imgs=8) {
require(imager)
img <- images.bw[index,,,]
n_images <- dim(img)[3]
par(mfrow=c(par_imgs,par_imgs), oma=c(0,0,0,0),
mai=c(0.05,0.05,0.05,0.05),ann=FALSE,ask=FALSE)
for(i in 1:n_images){
img.bwmat <- as.cimg(img[,,i])
if(!is.null(images.lab)){
lab = labels[[1]][images.lab[[index]]]
}
plot(img.bwmat,axes=FALSE,ann=FALSE)
}
par(mfrow=c(1,1))
}
drawImage_conv_weights <- function(weights_conv, par_imgs=8) {
require(imager)
n_images <- dim(weights_conv)[4]
par(mfrow=c(par_imgs,par_imgs), oma=c(0,0,0,0),
mai=c(0.05,0.05,0.05,0.05),ann=FALSE,ask=FALSE)
for(i in 1:n_images){
img.r.mat <- as.cimg(weights_conv[,,1,i])
img.g.mat <- as.cimg(weights_conv[,,2,i])
img.b.mat <- as.cimg(weights_conv[,,3,i])
img.col.mat <- imappend(list(img.r.mat,img.g.mat,img.b.mat),"c")
plot(img.col.mat,axes=FALSE,ann=FALSE)
}
par(mfrow=c(1,1))
}
flatten_conv_layer <- function(layer){
layer_shape = layer$get_shape()
num_features =
prod(c(layer_shape$as_list()[[2]],layer_shape$as_list()[[3]],layer_
shape$as_list()[[4]]))
num_features = prod(c(layer_shape$as_list()[[2]],layer_shape$as_list()[[3]],layer_shape$as_list()[[4]]))
flatten_conv_layer <- function(layer){
layer_shape = layer$get_shape()
num_features = prod(c(layer_shape$as_list()[[2]],layer_shape$as_list()[[3]],layer_shape$as_list()[[4]]))
layer_flat = tf$reshape(layer, shape(-1, num_features))
return(list("layer_flat"=layer_flat, "num_features"=num_features))
}
create_fc_layer <- function(input,
num_inputs,
num_outputs,
use_relu=True)
{
weights = weight_variable(shape=shape(num_inputs, num_outputs))
biases = bias_variable(shape=shape(num_outputs))
layer = tf$matmul(input, weights) + biases
if(use_relu){
layer = tf$nn$relu(layer)
}
return(layer)
}
library(tensorflow)
sess = tf$Session()
x = tf$placeholder(tf$float32, shape=shape(NULL, img_size_flat),
name='x')
x_image = tf$reshape(x, shape(-1L, img_size, img_size,
num_channels))
y_true = tf$placeholder(tf$float32, shape=shape(NULL, num_classes),
name='y_true')
y_true_cls = tf$argmax(y_true, dimension=1L)
conv1 <- create_conv_layer(input=x_image,
num_input_channels=num_channels,
filter_size=filter_size1,
num_filters=num_filters1,
use_pooling=TRUE)
layer_conv1 <- conv1$layer
conv1_images <- conv1$layer$eval(feed_dict = dict(x =
train_data$images, y_true = train_data$labels))
layer_conv1 <- conv1$layer
conv1_images <- conv1$layer$eval(feed_dict = dict(x = train_data$images, y_true = train_data$labels))
conv2 <- create_conv_layer(input=layer_conv1,
num_input_channels=num_filters1,
filter_size=filter_size2,
num_filters=num_filters2,
use_pooling=TRUE)
layer_conv2 <- conv2$layer
conv2_images <- conv2$layer$eval(feed_dict = dict(x =
train_data$images, y_true = train_data$labels))
layer_fc1 = create_fc_layer(input=layer_flat,
num_inputs=num_features,
num_outputs=fc_size,
use_relu=TRUE)
library(tensorflow)
np <- import("numpy")
tf$reset_default_graph()
sess <- tf$InteractiveSession()
sess$run(tf$global_variables_initializer())
train_batch_size = 128L
for (i in 1:100) {
spls <- sample(1:dim(train_data$images)[1],train_batch_size)
if (i %% 10 == 0) {
train_accuracy <- accuracy$eval(feed_dict = dict(
x = train_data$images[spls,], y_true = train_data$labels[spls,],
keep_prob = 1.0))
cat(sprintf("step %d, training accuracy %g\n", i, train_accuracy))
}
optimizer$run(feed_dict = dict(
x = train_data$images[spls,], y_true = train_data$labels[spls,],
keep_prob = 0.5))
}
test_true_class <- c(unlist(images.lab.test))
test_pred_class <- y_pred_cls$eval(feed_dict = dict(
x = test_data$images, y_true = test_data$labels, keep_prob = 1.0))
test_pred_class <- test_pred_class + 1
